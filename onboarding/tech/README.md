# Tech Onboarding Guide

## Step I: Processes and tools

Intention: You are familiar with our work environment and have relevant tooling installed

### Steps

* Read our [Coding Style Guides][coding-standards]
* Read about [Job stories][user-story] and do a job story
* Small introduction about workflow: boards, issues, milestones, sprint planning
* Relevant tooling: git, python, node, ...

[coding-standards]: /style-guide/
[user-story]: /job-stories/

## Part II: DataHub

Intention: you can publish data to the DataHub 

* have published a sample dataset to your account
* provided feedback on the experience

:::tip
Onboarder: Watch them via screen share (as they download) and have them take notes on this experience (what worked, what didn't)
:::

### Steps

* Sign up to datahub and follow instructiions
* Publish a Dataset: https://datahub.io/docs/getting-started/publishing-data
* Command line tool: data-cli - only provide documentation and then have them push sample dataset or file

## Part III: Packaging Data

Intention: you are able to curate a new (core) dataset and publish it to DataHub

:::tip
This is a task the Onboardee will go away and do on their own once they are briefed
:::

Agenda

* Frictionless Data and Data Packages: https://tech.datopian.com/frictionless/
* Our best practice curation and publishing: Data Package + DataFlows + Github (+ Actions)
	* DataFlows - https://github.com/datahq/dataflows
* **Practice task**: Curate a new dataset (look through registry and select one)
	* Select a dataset from https://github.com/datasets/awesome-data/issues
  * Turn it into a data package with a script to automate collecting the data

## Part IV: CKAN

Get started with CKAN: http://tech.datopian.com/ckan/

